{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns' , 100)\n",
    "pd.set_option('display.max_rows' , 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Deal with Datasets\n",
    "    - sales dataset\n",
    "    - buidlings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Deal with sales dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('nyc-rolling-sales.csv') # (84548, 22)\n",
    "# Encode BBL in the sales data\n",
    "BBL = []\n",
    "for i in range (len(sales)):\n",
    "    B1 = sales.BOROUGH[i]\n",
    "    B2 = sales.BLOCK[i]\n",
    "    L = sales.LOT[i]\n",
    "    bbl=str(B1)\n",
    "    if len(str(B2))==5:\n",
    "        bbl+=str(B2)\n",
    "    elif len(str(B2))==4:\n",
    "        bbl+='0'+str(B2)\n",
    "    elif len(str(B2))==3:\n",
    "        bbl+='00'+str(B2)\n",
    "    elif len(str(B2))==2:\n",
    "        bbl+='000'+str(B2)\n",
    "    elif len(str(B2))==1:\n",
    "        bbl+='0000'+str(B2)\n",
    "    else:\n",
    "        bbl+='00000'\n",
    "    if len(str(L))==4:\n",
    "        bbl+=str(L)\n",
    "    elif len(str(L))==3:\n",
    "        bbl+='0'+str(L)\n",
    "    elif len(str(L))==2:\n",
    "        bbl+='00'+str(L)\n",
    "    elif len(str(L))==1:\n",
    "        bbl+='000'+str(L)\n",
    "    else:\n",
    "        bbl+='0000'\n",
    "    BBL.append(float(bbl))\n",
    "    \n",
    "sales['BBL']=BBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['BBL', 'SALE PRICE']\n",
    "sales_price = sales[features] # (84548, 2)\n",
    "\n",
    "# Clean sales_price\n",
    "# 1. Replace ' -  ' by NaN\n",
    "sales_price = sales_price.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "sales_price = sales_price.dropna() # (69987, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Deal with buildings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "build3 = pd.read_csv('BK.csv', low_memory=False) # Brooklyn (3)\n",
    "build3['Borough Number'] = [1 for i in range (len(build3))] \n",
    "build2 = pd.read_csv('BX.csv', low_memory=False) # Bronx (2)\n",
    "build2['Borough Number'] = [1 for i in range (len(build2))] \n",
    "build1 = pd.read_csv('MN.csv', low_memory=False) # Manhattan (1)\n",
    "build1['Borough Number'] = [1 for i in range (len(build1))] \n",
    "build4 = pd.read_csv('QN.csv', low_memory=False) # Queens (4)\n",
    "build4['Borough Number'] = [1 for i in range (len(build4))] \n",
    "build5 = pd.read_csv('SI.csv', low_memory=False) # Staten Island (5)\n",
    "build5['Borough Number'] = [1 for i in range (len(build5))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select these features from buildings\n",
    "buildings_features = ['BBL', 'SchoolDist' , 'ZipCode', 'FireComp', 'LandUse', 'Easements', 'OwnerName', 'LotArea', \n",
    "                      'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea', \n",
    "                      'FactryArea', 'OtherArea', 'AreaSource', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', \n",
    "                      'LotFront', 'LotDepth', 'BldgFront', 'BldgDepth', 'ProxCode', 'IrrLotCode', 'LotType', \n",
    "                      'BsmtCode', 'AssessLand', 'AssessTot', 'YearBuilt', 'YearAlter1', 'YearAlter2', 'BuiltFAR', \n",
    "                      'ResidFAR', 'CommFAR', 'FacilFAR', 'XCoord', 'YCoord', 'ZoneMap', 'Borough Number']\n",
    "# Since the raw data of buildings have too many features, we only pick the ones from the above list\n",
    "build1 = build1[buildings_features ] # Manhattan, (42958, 43)\n",
    "build2 = build2[buildings_features ] # Bronx, (89830, 43)\n",
    "build3 = build3[buildings_features ] # Brooklyn, (277131, 43)\n",
    "build4 = build4[buildings_features ] # Queens, (324403, 43)\n",
    "build5 = build5[buildings_features ] # Staten Island, (124048, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55488\n",
      "42958\n",
      "89830\n",
      "277131\n",
      "324403\n",
      "124048\n"
     ]
    }
   ],
   "source": [
    "# Number of unique BBLs in each dataset\n",
    "print(len(sales_price.BBL.unique()))\n",
    "print(len(build1.BBL.unique()))\n",
    "print(len(build2.BBL.unique()))\n",
    "print(len(build3.BBL.unique()))\n",
    "print(len(build4.BBL.unique()))\n",
    "print(len(build5.BBL.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2815, 44)\n",
      "(5120, 44)\n",
      "(14858, 44)\n",
      "(11580, 44)\n",
      "(5152, 44)\n"
     ]
    }
   ],
   "source": [
    "# Compute common BBL for sales and buildings\n",
    "sales_drop = sales_price.drop_duplicates(['BBL']) \n",
    "build1_drop = build1.drop_duplicates(['BBL']) \n",
    "merge_Build1_sales = pd.merge(sales_drop, build1_drop, on='BBL')\n",
    "print(merge_Build1_sales.shape)\n",
    "\n",
    "build2_drop = build2.drop_duplicates(['BBL']) \n",
    "merge_Build2_sales = pd.merge(sales_drop, build2_drop, on='BBL')\n",
    "print(merge_Build2_sales.shape)\n",
    "\n",
    "build3_drop = build3.drop_duplicates(['BBL']) \n",
    "merge_Build3_sales = pd.merge(sales_drop, build3_drop, on='BBL')\n",
    "print(merge_Build3_sales.shape)\n",
    "\n",
    "build4_drop = build4.drop_duplicates(['BBL']) \n",
    "merge_Build4_sales = pd.merge(sales_drop, build4_drop, on='BBL')\n",
    "print(merge_Build4_sales.shape)\n",
    "\n",
    "build5_drop = build5.drop_duplicates(['BBL']) \n",
    "merge_Build5_sales = pd.merge(sales_drop, build5_drop, on='BBL')\n",
    "print(merge_Build5_sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5 Visualization of the sales price on 5 boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = pd.concat([build1, build2, build3, build4, build5], axis=0) # (858370, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(buildings, sales_price, on='BBL') # (52726, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings # Manhattan\n",
    "\n",
    "# 0. Drop non-indicative or duplicate-info columns\n",
    "#drop_columns = ['ZipCode', 'Borough Number']\n",
    "# Don't drop ZipCode\n",
    "drop_columns = ['Borough Number']\n",
    "buildings = buildings.drop(columns=drop_columns)\n",
    "\n",
    "# # 1. Replace ' -  ' by NaN\n",
    "# sales = sales.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "buildings = buildings.dropna()\n",
    "\n",
    "# 3. Drop catagorical columns with too many categories\n",
    "too_many_labels = ['FireComp', 'OwnerName', 'ZoneMap']\n",
    "buildings = buildings.drop(columns=too_many_labels)\n",
    "zipCode = buildings[['BBL', 'ZipCode']] # this information is useful for Part III of predictions\n",
    "\n",
    "# 4. Transform the data type to the desired type\n",
    "num_features = ['LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea',\n",
    "               'FactryArea', 'OtherArea', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront', 'LotDepth',\n",
    "               'BldgFront', 'BldgDepth', 'AssessLand', 'AssessTot', 'YearAlter1', 'YearAlter2', 'BuiltFAR']\n",
    "cat_features = ['SchoolDist', 'LandUse', 'Easements', 'AreaSource', 'ProxCode', 'IrrLotCode',\n",
    "               'LotType', 'BsmtCode']\n",
    "id_feature = ['BBL']\n",
    "\n",
    "for f in num_features:\n",
    "    if buildings[f].dtype != 'float64' or 'int64':\n",
    "        buildings[f] = buildings[f].astype('float64') #  convert non-numerical type to numerical\n",
    "\n",
    "for f in cat_features:\n",
    "    if buildings[f].dtype != 'O':\n",
    "        buildings[f] = buildings[f].astype('O')\n",
    "\n",
    "# 5. One-hot encode the categorical features\n",
    "# if the model does not like too many categories, we will drop 'BUILDING CLASS CATEGORY'\n",
    "obj_df = buildings[cat_features]\n",
    "num_df = buildings[num_features]\n",
    "BBL_df = buildings[id_feature]\n",
    "cat_df = pd.get_dummies(obj_df, drop_first=True)\n",
    "\n",
    "buildings = pd.concat([num_df, cat_df, BBL_df], axis=1) # (40695, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that has zipcode, BBL, sales price, sales price/sqrt-foot\n",
    "BBL = merge_df.BBL\n",
    "Area = merge_df.BldgArea # the total gross area in square feet\n",
    "Sales = pd.to_numeric(merge_df['SALE PRICE'])\n",
    "table1 = pd.concat([BBL, Area, Sales], axis=1)\n",
    "\n",
    "# merge zipCode and table1 to find the corresponding zip code\n",
    "table1 = pd.merge(zipCode, table1, on='BBL') # merge_df.shape is (7107, 66), zipCode.shape is (40695, 2)\n",
    "\n",
    "# Compute Per square-footage\n",
    "perSquFootPrice = pd.DataFrame({'UnitAreaPrice': table1['SALE PRICE'] / table1.BldgArea}) # (7107, 1)\n",
    "ZipCode = pd.DataFrame({'ZipCode': table1.ZipCode})\n",
    "\n",
    "perSquFootPrice = perSquFootPrice.replace(np.inf, np.nan)\n",
    "perSquFootPrice = perSquFootPrice.dropna() # (7070, 1)\n",
    "\n",
    "table1 = pd.concat([ZipCode, perSquFootPrice], axis=1)\n",
    "\n",
    "zipMap = pd.read_csv('zipcodes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode = table1.ZipCode.unique()\n",
    "Results = list(np.zeros((len(zipcode),3)))\n",
    "\n",
    "for i in range(len(zipcode)):\n",
    "    x = zipcode[i]\n",
    "    zip_df = table1.loc[table1.ZipCode == x] # returns a dataframe that has ZipCode == x\n",
    "    unitP = zip_df['UnitAreaPrice'].mean()\n",
    "    num = len(zip_df)\n",
    "    Results[i] = [x, unitP, num]\n",
    "    \n",
    "res1_df = pd.DataFrame(Results, columns = ['ZipCode' , 'UnitAreaPrice' , 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_map = pd.merge(res1_df, zipMap, on='ZipCode') # (42, 5)\n",
    "# need to read it to csv and plot it in colab\n",
    "table1_map.to_csv('Visul_5Boroughs_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare features, that is features in build1 - 5.\n",
    "1. Build1, Manhattan\n",
    "2. Build2, Bronx\n",
    "3. Build3, Brooklyn\n",
    "4. Build4, Queens\n",
    "5. Build5, Staten Island"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Manhattan.\n",
    "        - We find the best model is random forest regressor with depth 20, wich a test R^2 = 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = build1 # Manhattan\n",
    "\n",
    "# 0. Drop non-indicative or duplicate-info columns\n",
    "#drop_columns = ['ZipCode', 'Borough Number']\n",
    "# Don't drop ZipCode\n",
    "drop_columns = ['Borough Number']\n",
    "buildings = buildings.drop(columns=drop_columns)\n",
    "\n",
    "# # 1. Replace ' -  ' by NaN\n",
    "# sales = sales.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "buildings = buildings.dropna()\n",
    "\n",
    "# 3. Drop catagorical columns with too many categories\n",
    "too_many_labels = ['FireComp', 'OwnerName', 'ZoneMap']\n",
    "buildings = buildings.drop(columns=too_many_labels)\n",
    "zipCode = buildings[['BBL', 'ZipCode']] # this information is useful for Part III of predictions\n",
    "\n",
    "# 4. Transform the data type to the desired type\n",
    "num_features = ['LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea',\n",
    "               'FactryArea', 'OtherArea', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront', 'LotDepth',\n",
    "               'BldgFront', 'BldgDepth', 'AssessLand', 'AssessTot', 'YearAlter1', 'YearAlter2', 'BuiltFAR']\n",
    "cat_features = ['SchoolDist', 'LandUse', 'Easements', 'AreaSource', 'ProxCode', 'IrrLotCode',\n",
    "               'LotType', 'BsmtCode']\n",
    "id_feature = ['BBL']\n",
    "\n",
    "for f in num_features:\n",
    "    if buildings[f].dtype != 'float64' or 'int64':\n",
    "        buildings[f] = buildings[f].astype('float64') #  convert non-numerical type to numerical\n",
    "\n",
    "for f in cat_features:\n",
    "    if buildings[f].dtype != 'O':\n",
    "        buildings[f] = buildings[f].astype('O')\n",
    "\n",
    "# 5. One-hot encode the categorical features\n",
    "# if the model does not like too many categories, we will drop 'BUILDING CLASS CATEGORY'\n",
    "obj_df = buildings[cat_features]\n",
    "num_df = buildings[num_features]\n",
    "BBL_df = buildings[id_feature]\n",
    "cat_df = pd.get_dummies(obj_df, drop_first=True)\n",
    "\n",
    "buildings = pd.concat([num_df, cat_df, BBL_df], axis=1) # (40695, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is  0.9232386388842991\n",
      "The score on the entire dataset is  0.901935474001108\n"
     ]
    }
   ],
   "source": [
    "# merge data\n",
    "merge_df = pd.merge(sales_price, buildings, on='BBL') # (7107, 66)\n",
    "\n",
    "# train and test\n",
    "train_df, test_df = train_test_split(merge_df, test_size=0.2, random_state=2)\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "# Deeper Forest, the best model!\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "print('The test score is ', forest_model.score(test_df[features], test_df['SALE PRICE']))\n",
    "\n",
    "print('The score on the entire dataset is ', forest_model.score(merge_df[features], merge_df['SALE PRICE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire build dataset\n",
    "merge_df = buildings # before, merge_df is (7107, 66) when training the model, but now is (40695, 65)\n",
    "\n",
    "# Predicting\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "\n",
    "result1 = forest_model.predict(merge_df[features]) # this is the model trained before\n",
    "result1 = pd.DataFrame({'PredPrice': result1})\n",
    "\n",
    "# Create a dataframe that has zipcode, BBL, sales price, sales price/sqrt-foot\n",
    "BBL = merge_df.BBL\n",
    "Area = merge_df.BldgArea # the total gross area in square feet.\n",
    "table1 = pd.concat([BBL, Area, result1], axis=1)\n",
    "# merge zipCode and table1 to find the corresponding zip code\n",
    "table1 = pd.merge(zipCode, table1, on='BBL') # merge_df.shape is (7107, 66), zipCode.shape is (40695, 2)\n",
    "table1.head() # (7107, 4)\n",
    "# Compute Per square-footage\n",
    "perSquFootPrice = pd.DataFrame({'UnitAreaPrice': table1.PredPrice / table1.BldgArea}) # (7107, 1)\n",
    "ZipCode = pd.DataFrame({'ZipCode': table1.ZipCode})\n",
    "\n",
    "perSquFootPrice = perSquFootPrice.replace(np.inf, np.nan)\n",
    "perSquFootPrice = perSquFootPrice.dropna() # (7070, 1)\n",
    "\n",
    "table1 = pd.concat([ZipCode, perSquFootPrice], axis=1)\n",
    "\n",
    "zipMap = pd.read_csv('zipcodes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode = table1.ZipCode.unique()\n",
    "Results = list(np.zeros((len(zipcode),3)))\n",
    "\n",
    "for i in range(len(zipcode)):\n",
    "    x = zipcode[i]\n",
    "    zip_df = table1.loc[table1.ZipCode == x] # returns a dataframe that has ZipCode == x\n",
    "    unitP = zip_df['UnitAreaPrice'].mean()\n",
    "    num = len(zip_df)\n",
    "    Results[i] = [x, unitP, num]\n",
    "    \n",
    "res1_df = pd.DataFrame(Results, columns = ['ZipCode' , 'UnitAreaPrice' , 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_map = pd.merge(res1_df, zipMap, on='ZipCode') # (42, 5)\n",
    "# need to read it to csv and plot it in colab\n",
    "table1_map.to_csv('Manhattan_map.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bronx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = build2 # Bronx\n",
    "\n",
    "# 0. Drop non-indicative or duplicate-info columns\n",
    "#drop_columns = ['ZipCode', 'Borough Number']\n",
    "# Don't drop ZipCode\n",
    "drop_columns = ['Borough Number']\n",
    "buildings = buildings.drop(columns=drop_columns)\n",
    "\n",
    "# # 1. Replace ' -  ' by NaN\n",
    "# sales = sales.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "buildings = buildings.dropna()\n",
    "\n",
    "# 3. Drop catagorical columns with too many categories\n",
    "too_many_labels = ['FireComp', 'OwnerName', 'ZoneMap']\n",
    "buildings = buildings.drop(columns=too_many_labels)\n",
    "zipCode = buildings[['BBL', 'ZipCode']] # this information is useful for Part III of predictions\n",
    "\n",
    "# 4. Transform the data type to the desired type\n",
    "num_features = ['LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea',\n",
    "               'FactryArea', 'OtherArea', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront', 'LotDepth',\n",
    "               'BldgFront', 'BldgDepth', 'AssessLand', 'AssessTot', 'YearAlter1', 'YearAlter2', 'BuiltFAR']\n",
    "cat_features = ['SchoolDist', 'LandUse', 'Easements', 'AreaSource', 'ProxCode', 'IrrLotCode',\n",
    "               'LotType', 'BsmtCode']\n",
    "id_feature = ['BBL']\n",
    "\n",
    "for f in num_features:\n",
    "    if buildings[f].dtype != 'float64' or 'int64':\n",
    "        buildings[f] = buildings[f].astype('float64') #  convert non-numerical type to numerical\n",
    "\n",
    "for f in cat_features:\n",
    "    if buildings[f].dtype != 'O':\n",
    "        buildings[f] = buildings[f].astype('O')\n",
    "\n",
    "# 5. One-hot encode the categorical features\n",
    "# if the model does not like too many categories, we will drop 'BUILDING CLASS CATEGORY'\n",
    "obj_df = buildings[cat_features]\n",
    "num_df = buildings[num_features]\n",
    "BBL_df = buildings[id_feature]\n",
    "cat_df = pd.get_dummies(obj_df, drop_first=True)\n",
    "\n",
    "buildings = pd.concat([num_df, cat_df, BBL_df], axis=1) # (40695, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is  0.06319608897726103\n",
      "The score on the entire dataset is  0.14628867240642696\n"
     ]
    }
   ],
   "source": [
    "# merge data\n",
    "merge_df = pd.merge(sales_price, buildings, on='BBL') # (7107, 66)\n",
    "\n",
    "# train and test\n",
    "train_df, test_df = train_test_split(merge_df, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "# Linear\n",
    "ridge = Ridge(alpha=1.0, fit_intercept=True, normalize=True)\n",
    "features = list(set(train_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "# \n",
    "ridge_model = ridge.fit(train_df[features], train_df['SALE PRICE'])\n",
    "print('The test score is ', ridge_model.score(test_df[features], test_df['SALE PRICE']))\n",
    "\n",
    "print('The score on the entire dataset is ', ridge_model.score(merge_df[features], merge_df['SALE PRICE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire build dataset\n",
    "merge_df = buildings # before, merge_df is (7107, 66) when training the model, but now is (40695, 65)\n",
    "\n",
    "# Predicting\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "\n",
    "result1 = forest_model.predict(merge_df[features]) # this is the model trained before\n",
    "result1 = pd.DataFrame({'PredPrice': result1})\n",
    "\n",
    "# Create a dataframe that has zipcode, BBL, sales price, sales price/sqrt-foot\n",
    "BBL = merge_df.BBL\n",
    "Area = merge_df.BldgArea # the total gross area in square feet.\n",
    "table1 = pd.concat([BBL, Area, result1], axis=1)\n",
    "# merge zipCode and table1 to find the corresponding zip code\n",
    "table1 = pd.merge(zipCode, table1, on='BBL') # merge_df.shape is (7107, 66), zipCode.shape is (40695, 2)\n",
    "table1.head() # (7107, 4)\n",
    "# Compute Per square-footage\n",
    "perSquFootPrice = pd.DataFrame({'UnitAreaPrice': table1.PredPrice / table1.BldgArea}) # (7107, 1)\n",
    "ZipCode = pd.DataFrame({'ZipCode': table1.ZipCode})\n",
    "\n",
    "perSquFootPrice = perSquFootPrice.replace(np.inf, np.nan)\n",
    "perSquFootPrice = perSquFootPrice.dropna() # (7070, 1)\n",
    "\n",
    "table1 = pd.concat([ZipCode, perSquFootPrice], axis=1)\n",
    "\n",
    "zipMap = pd.read_csv('zipcodes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode = table1.ZipCode.unique()\n",
    "Results = list(np.zeros((len(zipcode),3)))\n",
    "\n",
    "for i in range(len(zipcode)):\n",
    "    x = zipcode[i]\n",
    "    zip_df = table1.loc[table1.ZipCode == x] # returns a dataframe that has ZipCode == x\n",
    "    unitP = zip_df['UnitAreaPrice'].mean()\n",
    "    num = len(zip_df)\n",
    "    Results[i] = [x, unitP, num]\n",
    "    \n",
    "res1_df = pd.DataFrame(Results, columns = ['ZipCode' , 'UnitAreaPrice' , 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_map = pd.merge(res1_df, zipMap, on='ZipCode') # (42, 5)\n",
    "# need to read it to csv and plot it in colab\n",
    "table1_map.to_csv('Bronx_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = build3 # Brooklyn\n",
    "\n",
    "# 0. Drop non-indicative or duplicate-info columns\n",
    "#drop_columns = ['ZipCode', 'Borough Number']\n",
    "# Don't drop ZipCode\n",
    "drop_columns = ['Borough Number']\n",
    "buildings = buildings.drop(columns=drop_columns)\n",
    "\n",
    "# # 1. Replace ' -  ' by NaN\n",
    "# sales = sales.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "buildings = buildings.dropna()\n",
    "\n",
    "# 3. Drop catagorical columns with too many categories\n",
    "too_many_labels = ['FireComp', 'OwnerName', 'ZoneMap']\n",
    "buildings = buildings.drop(columns=too_many_labels)\n",
    "zipCode = buildings[['BBL', 'ZipCode']] # this information is useful for Part III of predictions\n",
    "\n",
    "# 4. Transform the data type to the desired type\n",
    "num_features = ['LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea',\n",
    "               'FactryArea', 'OtherArea', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront', 'LotDepth',\n",
    "               'BldgFront', 'BldgDepth', 'AssessLand', 'AssessTot', 'YearAlter1', 'YearAlter2', 'BuiltFAR']\n",
    "cat_features = ['SchoolDist', 'LandUse', 'Easements', 'AreaSource', 'ProxCode', 'IrrLotCode',\n",
    "               'LotType', 'BsmtCode']\n",
    "id_feature = ['BBL']\n",
    "\n",
    "for f in num_features:\n",
    "    if buildings[f].dtype != 'float64' or 'int64':\n",
    "        buildings[f] = buildings[f].astype('float64') #  convert non-numerical type to numerical\n",
    "\n",
    "for f in cat_features:\n",
    "    if buildings[f].dtype != 'O':\n",
    "        buildings[f] = buildings[f].astype('O')\n",
    "\n",
    "# 5. One-hot encode the categorical features\n",
    "# if the model does not like too many categories, we will drop 'BUILDING CLASS CATEGORY'\n",
    "obj_df = buildings[cat_features]\n",
    "num_df = buildings[num_features]\n",
    "BBL_df = buildings[id_feature]\n",
    "cat_df = pd.get_dummies(obj_df, drop_first=True)\n",
    "\n",
    "buildings = pd.concat([num_df, cat_df, BBL_df], axis=1) # (40695, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is  -0.01301712733809568\n",
      "The score on the entire dataset is  0.6883358035144499\n"
     ]
    }
   ],
   "source": [
    "# merge data\n",
    "merge_df = pd.merge(sales_price, buildings, on='BBL') # (7107, 66)\n",
    "\n",
    "# train and test\n",
    "train_df, test_df = train_test_split(merge_df, test_size=0.2, random_state=2)\n",
    "\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=65, random_state=0, n_estimators=40)\n",
    "\n",
    "# Deeper Forest, the best model!\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "print('The test score is ', forest_model.score(test_df[features], test_df['SALE PRICE']))\n",
    "\n",
    "print('The score on the entire dataset is ', forest_model.score(merge_df[features], merge_df['SALE PRICE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire build dataset\n",
    "merge_df = buildings # before, merge_df is (7107, 66) when training the model, but now is (40695, 65)\n",
    "\n",
    "# Predicting\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "\n",
    "result1 = forest_model.predict(merge_df[features]) # this is the model trained before\n",
    "result1 = pd.DataFrame({'PredPrice': result1})\n",
    "\n",
    "# Create a dataframe that has zipcode, BBL, sales price, sales price/sqrt-foot\n",
    "BBL = merge_df.BBL\n",
    "Area = merge_df.BldgArea # the total gross area in square feet.\n",
    "table1 = pd.concat([BBL, Area, result1], axis=1)\n",
    "# merge zipCode and table1 to find the corresponding zip code\n",
    "table1 = pd.merge(zipCode, table1, on='BBL') # merge_df.shape is (7107, 66), zipCode.shape is (40695, 2)\n",
    "table1.head() # (7107, 4)\n",
    "# Compute Per square-footage\n",
    "perSquFootPrice = pd.DataFrame({'UnitAreaPrice': table1.PredPrice / table1.BldgArea}) # (7107, 1)\n",
    "ZipCode = pd.DataFrame({'ZipCode': table1.ZipCode})\n",
    "\n",
    "perSquFootPrice = perSquFootPrice.replace(np.inf, np.nan)\n",
    "perSquFootPrice = perSquFootPrice.dropna() # (7070, 1)\n",
    "\n",
    "table1 = pd.concat([ZipCode, perSquFootPrice], axis=1)\n",
    "\n",
    "zipMap = pd.read_csv('zipcodes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode = table1.ZipCode.unique()\n",
    "Results = list(np.zeros((len(zipcode),3)))\n",
    "\n",
    "for i in range(len(zipcode)):\n",
    "    x = zipcode[i]\n",
    "    zip_df = table1.loc[table1.ZipCode == x] # returns a dataframe that has ZipCode == x\n",
    "    unitP = zip_df['UnitAreaPrice'].mean()\n",
    "    num = len(zip_df)\n",
    "    Results[i] = [x, unitP, num]\n",
    "    \n",
    "res1_df = pd.DataFrame(Results, columns = ['ZipCode' , 'UnitAreaPrice' , 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_map = pd.merge(res1_df, zipMap, on='ZipCode') # (42, 5)\n",
    "# need to read it to csv and plot it in colab\n",
    "table1_map.to_csv('Brooklyn_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Queens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = build4 # Queens\n",
    "\n",
    "# 0. Drop non-indicative or duplicate-info columns\n",
    "#drop_columns = ['ZipCode', 'Borough Number']\n",
    "# Don't drop ZipCode\n",
    "drop_columns = ['Borough Number']\n",
    "buildings = buildings.drop(columns=drop_columns)\n",
    "\n",
    "# # 1. Replace ' -  ' by NaN\n",
    "# sales = sales.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "buildings = buildings.dropna()\n",
    "\n",
    "# 3. Drop catagorical columns with too many categories\n",
    "too_many_labels = ['FireComp', 'OwnerName', 'ZoneMap']\n",
    "buildings = buildings.drop(columns=too_many_labels)\n",
    "zipCode = buildings[['BBL', 'ZipCode']] # this information is useful for Part III of predictions\n",
    "\n",
    "# 4. Transform the data type to the desired type\n",
    "num_features = ['LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea',\n",
    "               'FactryArea', 'OtherArea', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront', 'LotDepth',\n",
    "               'BldgFront', 'BldgDepth', 'AssessLand', 'AssessTot', 'YearAlter1', 'YearAlter2', 'BuiltFAR']\n",
    "cat_features = ['SchoolDist', 'LandUse', 'Easements', 'AreaSource', 'ProxCode', 'IrrLotCode',\n",
    "               'LotType', 'BsmtCode']\n",
    "id_feature = ['BBL']\n",
    "\n",
    "for f in num_features:\n",
    "    if buildings[f].dtype != 'float64' or 'int64':\n",
    "        buildings[f] = buildings[f].astype('float64') #  convert non-numerical type to numerical\n",
    "\n",
    "for f in cat_features:\n",
    "    if buildings[f].dtype != 'O':\n",
    "        buildings[f] = buildings[f].astype('O')\n",
    "\n",
    "# 5. One-hot encode the categorical features\n",
    "# if the model does not like too many categories, we will drop 'BUILDING CLASS CATEGORY'\n",
    "obj_df = buildings[cat_features]\n",
    "num_df = buildings[num_features]\n",
    "BBL_df = buildings[id_feature]\n",
    "cat_df = pd.get_dummies(obj_df, drop_first=True)\n",
    "\n",
    "buildings = pd.concat([num_df, cat_df, BBL_df], axis=1) # (40695, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is  0.2608671902515134\n",
      "The score on the entire dataset is  0.837152182420502\n"
     ]
    }
   ],
   "source": [
    "# merge data\n",
    "merge_df = pd.merge(sales_price, buildings, on='BBL') # (7107, 66)\n",
    "\n",
    "# train and test\n",
    "train_df, test_df = train_test_split(merge_df, test_size=0.2, random_state=2)\n",
    "\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=100, random_state=0, n_estimators=60)\n",
    "\n",
    "# Deeper Forest, the best model!\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "print('The test score is ', forest_model.score(test_df[features], test_df['SALE PRICE']))\n",
    "\n",
    "print('The score on the entire dataset is ', forest_model.score(merge_df[features], merge_df['SALE PRICE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire build dataset\n",
    "merge_df = buildings # before, merge_df is (7107, 66) when training the model, but now is (40695, 65)\n",
    "\n",
    "# Predicting\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "\n",
    "result1 = forest_model.predict(merge_df[features]) # this is the model trained before\n",
    "result1 = pd.DataFrame({'PredPrice': result1})\n",
    "\n",
    "# Create a dataframe that has zipcode, BBL, sales price, sales price/sqrt-foot\n",
    "BBL = merge_df.BBL\n",
    "Area = merge_df.BldgArea # the total gross area in square feet.\n",
    "table1 = pd.concat([BBL, Area, result1], axis=1)\n",
    "# merge zipCode and table1 to find the corresponding zip code\n",
    "table1 = pd.merge(zipCode, table1, on='BBL') # merge_df.shape is (7107, 66), zipCode.shape is (40695, 2)\n",
    "table1.head() # (7107, 4)\n",
    "# Compute Per square-footage\n",
    "perSquFootPrice = pd.DataFrame({'UnitAreaPrice': table1.PredPrice / table1.BldgArea}) # (7107, 1)\n",
    "ZipCode = pd.DataFrame({'ZipCode': table1.ZipCode})\n",
    "\n",
    "perSquFootPrice = perSquFootPrice.replace(np.inf, np.nan)\n",
    "perSquFootPrice = perSquFootPrice.dropna() # (7070, 1)\n",
    "\n",
    "table1 = pd.concat([ZipCode, perSquFootPrice], axis=1)\n",
    "\n",
    "zipMap = pd.read_csv('zipcodes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode = table1.ZipCode.unique()\n",
    "Results = list(np.zeros((len(zipcode),3)))\n",
    "\n",
    "for i in range(len(zipcode)):\n",
    "    x = zipcode[i]\n",
    "    zip_df = table1.loc[table1.ZipCode == x] # returns a dataframe that has ZipCode == x\n",
    "    unitP = zip_df['UnitAreaPrice'].mean()\n",
    "    num = len(zip_df)\n",
    "    Results[i] = [x, unitP, num]\n",
    "    \n",
    "res1_df = pd.DataFrame(Results, columns = ['ZipCode' , 'UnitAreaPrice' , 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_map = pd.merge(res1_df, zipMap, on='ZipCode') # (42, 5)\n",
    "# need to read it to csv and plot it in colab\n",
    "table1_map.to_csv('Queens_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Staten Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = build5 # Staten Island\n",
    "\n",
    "# 0. Drop non-indicative or duplicate-info columns\n",
    "#drop_columns = ['ZipCode', 'Borough Number']\n",
    "# Don't drop ZipCode\n",
    "drop_columns = ['Borough Number']\n",
    "buildings = buildings.drop(columns=drop_columns)\n",
    "\n",
    "# # 1. Replace ' -  ' by NaN\n",
    "# sales = sales.replace(' -  ', np.nan)\n",
    "\n",
    "# 2. Drop NaN\n",
    "buildings = buildings.dropna()\n",
    "\n",
    "# 3. Drop catagorical columns with too many categories\n",
    "too_many_labels = ['FireComp', 'OwnerName', 'ZoneMap']\n",
    "buildings = buildings.drop(columns=too_many_labels)\n",
    "zipCode = buildings[['BBL', 'ZipCode']] # this information is useful for Part III of predictions\n",
    "\n",
    "# 4. Transform the data type to the desired type\n",
    "num_features = ['LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea', 'GarageArea', 'StrgeArea',\n",
    "               'FactryArea', 'OtherArea', 'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront', 'LotDepth',\n",
    "               'BldgFront', 'BldgDepth', 'AssessLand', 'AssessTot', 'YearAlter1', 'YearAlter2', 'BuiltFAR']\n",
    "cat_features = ['SchoolDist', 'LandUse', 'Easements', 'AreaSource', 'ProxCode', 'IrrLotCode',\n",
    "               'LotType', 'BsmtCode']\n",
    "id_feature = ['BBL']\n",
    "\n",
    "for f in num_features:\n",
    "    if buildings[f].dtype != 'float64' or 'int64':\n",
    "        buildings[f] = buildings[f].astype('float64') #  convert non-numerical type to numerical\n",
    "\n",
    "for f in cat_features:\n",
    "    if buildings[f].dtype != 'O':\n",
    "        buildings[f] = buildings[f].astype('O')\n",
    "\n",
    "# 5. One-hot encode the categorical features\n",
    "# if the model does not like too many categories, we will drop 'BUILDING CLASS CATEGORY'\n",
    "obj_df = buildings[cat_features]\n",
    "num_df = buildings[num_features]\n",
    "BBL_df = buildings[id_feature]\n",
    "cat_df = pd.get_dummies(obj_df, drop_first=True)\n",
    "\n",
    "buildings = pd.concat([num_df, cat_df, BBL_df], axis=1) # (40695, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is  0.674526769360178\n",
      "The score on the entire dataset is  0.8068279832122394\n"
     ]
    }
   ],
   "source": [
    "# merge data\n",
    "merge_df = pd.merge(sales_price, buildings, on='BBL') # (7107, 66)\n",
    "\n",
    "# train and test\n",
    "train_df, test_df = train_test_split(merge_df, test_size=0.2, random_state=2)\n",
    "\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "\n",
    "# Deeper Forest, the best model!\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "print('The test score is ', forest_model.score(test_df[features], test_df['SALE PRICE']))\n",
    "\n",
    "print('The score on the entire dataset is ', forest_model.score(merge_df[features], merge_df['SALE PRICE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire build dataset\n",
    "merge_df = buildings # before, merge_df is (7107, 66) when training the model, but now is (40695, 65)\n",
    "\n",
    "# Predicting\n",
    "features = list(set(merge_df.columns)-{'SALE PRICE'})\n",
    "\n",
    "randomforest_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\n",
    "forest_model = randomforest_reg.fit(train_df[features], train_df['SALE PRICE'])\n",
    "\n",
    "result1 = forest_model.predict(merge_df[features]) # this is the model trained before\n",
    "result1 = pd.DataFrame({'PredPrice': result1})\n",
    "\n",
    "# Create a dataframe that has zipcode, BBL, sales price, sales price/sqrt-foot\n",
    "BBL = merge_df.BBL\n",
    "Area = merge_df.BldgArea # the total gross area in square feet.\n",
    "table1 = pd.concat([BBL, Area, result1], axis=1)\n",
    "# merge zipCode and table1 to find the corresponding zip code\n",
    "table1 = pd.merge(zipCode, table1, on='BBL') # merge_df.shape is (7107, 66), zipCode.shape is (40695, 2)\n",
    "table1.head() # (7107, 4)\n",
    "# Compute Per square-footage\n",
    "perSquFootPrice = pd.DataFrame({'UnitAreaPrice': table1.PredPrice / table1.BldgArea}) # (7107, 1)\n",
    "ZipCode = pd.DataFrame({'ZipCode': table1.ZipCode})\n",
    "\n",
    "perSquFootPrice = perSquFootPrice.replace(np.inf, np.nan)\n",
    "perSquFootPrice = perSquFootPrice.dropna() # (7070, 1)\n",
    "\n",
    "table1 = pd.concat([ZipCode, perSquFootPrice], axis=1)\n",
    "\n",
    "zipMap = pd.read_csv('zipcodes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode = table1.ZipCode.unique()\n",
    "Results = list(np.zeros((len(zipcode),3)))\n",
    "\n",
    "for i in range(len(zipcode)):\n",
    "    x = zipcode[i]\n",
    "    zip_df = table1.loc[table1.ZipCode == x] # returns a dataframe that has ZipCode == x\n",
    "    unitP = zip_df['UnitAreaPrice'].mean()\n",
    "    num = len(zip_df)\n",
    "    Results[i] = [x, unitP, num]\n",
    "    \n",
    "res1_df = pd.DataFrame(Results, columns = ['ZipCode' , 'UnitAreaPrice' , 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_map = pd.merge(res1_df, zipMap, on='ZipCode') # (42, 5)\n",
    "# need to read it to csv and plot it in colab\n",
    "table1_map.to_csv('StatenIsland_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
